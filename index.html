<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization</title>
    <meta name="description" content="One-shot 6D pose estimation with generative domain randomization">
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/gsap@3.11.4/dist/gsap.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            scroll-behavior: smooth;
        }
        .gradient-text {
            background: linear-gradient(90deg, #3b82f6, #8b5cf6);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
        }
        .section-card {
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .section-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 15px rgba(0, 0, 0, 0.1);
        }
        #canvas-container {
            position: relative;
            width: 100%;
            height: 500px;
            overflow: hidden;
            border-radius: 12px;
        }
        .nav-link {
            position: relative;
        }
        .nav-link::after {
            content: '';
            position: absolute;
            width: 0;
            height: 2px;
            bottom: -2px;
            left: 0;
            background-color: #3b82f6;
            transition: width 0.3s ease;
        }
        .nav-link:hover::after {
            width: 100%;
        }
    </style>
</head>
<body class="bg-gray-50">
    <!-- Animated Header -->
    <header class="relative overflow-hidden bg-gradient-to-r from-blue-500 to-purple-600 text-white" style="padding-top: 27%;">
        <!-- 使用padding-top技巧来维持16:9的宽高比 -->
        <video class="absolute inset-0 w-full h-full object-cover opacity-30" autoplay loop muted playsinline>
            <source src="videos/bg.mp4" type="video/mp4">
        </video>
        <div class="absolute inset-0 flex flex-col justify-center items-center text-center z-10">
            <h1 class="text-4xl md:text-6xl font-bold mb-6">One View, Many Worlds</h1>
            <p class="text-xl md:text-2xl mb-8">Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation</p>
            
            <div class="flex flex-wrap justify-center gap-4 mb-8">
                <a href="https://arxiv.org" class="bg-white text-blue-600 px-4 py-2 rounded-full font-medium hover:bg-blue-50 transition">
                    <i class="fas fa-file-alt mr-2"></i> arXiv Paper
                </a>
                <a href="https://huggingface.co/spaces/ZhengGeng/OnePoseviaGen" class="bg-white text-purple-600 px-4 py-2 rounded-full font-medium hover:bg-purple-50 transition">
                    <i class="fas fa-rocket mr-2"></i> Huggingface Demo
                </a>
                <a href="https://github.com/gzwsama/OnePoseviaGen" class="bg-white text-gray-800 px-4 py-2 rounded-full font-medium hover:bg-gray-100 transition">
                    <i class="fab fa-github mr-2"></i> GitHub Code
                </a>
            </div>
            
            <p class="text-lg">Zheng Geng, Nan Wang, Shaocong Xu, Bohan Li, Zhaoxi Chen, Chongjie Ye, Sida Peng, Hao Zhao</p>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="sticky top-0 bg-white shadow-sm z-50">
        <div class="container mx-auto px-4 py-4">
            <div class="flex justify-center space-x-6">
                <a href="#abstract" class="nav-link text-gray-700 hover:text-blue-600">Abstract</a>
                <a href="#overview" class="nav-link text-gray-700 hover:text-blue-600">Overview</a>
                <a href="#video" class="nav-link text-gray-700 hover:text-blue-600">Video</a>
                <a href="#demo" class="nav-link text-gray-700 hover:text-blue-600">Demo</a>
                <a href="#experiments" class="nav-link text-gray-700 hover:text-blue-600">Experiments</a>
            </div>
        </div>
    </nav>

    <main class="container mx-auto px-4 py-12">
        <!-- Abstract Section -->
        <section id="abstract" class="mb-20">
            <div class="bg-white rounded-xl p-8 section-card">
                <h2 class="text-3xl font-bold text-center mb-8 gradient-text">Abstract</h2>
                <div class="prose max-w-4xl mx-auto">
                    <p class="text-gray-700 leading-relaxed">
                        Estimating the 6D pose of arbitrary objects from a single reference image is a critical yet challenging task in robotics, especially considering the long-tail distribution of real-world instances. While category-level and model-based approaches have achieved notable progress, they remain limited in generalizing to unseen objects under one-shot settings. In this work, we propose a novel pipeline for fast and accurate one-shot 6D pose and scale estimation. Leveraging recent advances in single-view 3D generation, we first build high-fidelity textured meshes without requiring known object poses. To resolve scale ambiguity, we introduce a coarse-to-fine alignment module that estimates both object size and initial pose by matching 2D-3D features with depth information. We then generate a diversified set of plausible 3D models using text-guided generative augmentation and render them with Blender to synthesize large-scale, domain-randomized training data for pose estimation. This synthetic data bridges the domain gap and enables robust fine-tuning of pose estimators. Our method achieves state-of-the-art results on several 6D pose benchmarks, and we further validate its effectiveness on a newly collected in-the-wild dataset. Finally, we integrate our system with a dexterous hand, demonstrating its robustness in real-world robotic grasping tasks. All code, data, and models will be released to foster future research.
                    </p>
                </div>
                
                <div class="mt-12">
                    <h3 class="text-xl font-semibold text-center mb-4">Interactive Examples</h3>
                    
                    <!-- Main display area -->
                    <div class="max-w-4xl mx-auto display-container relative">
                        <div id="loadingIndicator" class="absolute inset-0 flex items-center justify-center bg-white bg-opacity-75 z-10 hidden">
                            <div class="w-8 h-8 border-4 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                        </div>
                        <iframe id="mainDisplay" class="w-full h-96 border-2 border-gray-200 rounded-lg shadow" frameborder="0" src=""></iframe>
                    </div>
                    
                    <!-- Example selector gallery -->
                    <div class="example-selector mt-6 flex flex-wrap justify-center gap-3">
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/1/index.html">
                            <img src="examples/1/000000.jpg" alt="Example 1" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 1</p>
                        </div>
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/2/index.html">
                            <img src="examples/2/000000.jpg" alt="Example 2" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 2</p>
                        </div>
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/3/index.html">
                            <img src="examples/3/000000.jpg" alt="Example 3" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 3</p>
                        </div>
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/4/index.html">
                            <img src="examples/4/000000.jpg" alt="Example 4" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 4</p>
                        </div>
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/5/index.html">
                            <img src="examples/5/000000.jpg" alt="Example 5" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 5</p>
                        </div>
                        <div class="example-thumbnail cursor-pointer transition-transform hover:scale-105 active:bg-blue-50" 
                            data-example="examples/6/index.html">
                            <img src="examples/6/000000.jpg" alt="Example 6" class="w-24 h-16 object-cover rounded">
                            <p class="text-xs text-center mt-1">Example 6</p>
                        </div>
                    </div>
                </div>

                <script>
                // 等待 DOM 加载完成
                document.addEventListener('DOMContentLoaded', function() {
                    const iframe = document.getElementById('mainDisplay');
                    const loadingIndicator = document.getElementById('loadingIndicator');
                    const thumbnails = document.querySelectorAll('.example-thumbnail');
                    
                    // 加载指定示例的函数
                    function loadExample(examplePath) {
                        // 显示加载指示器
                        loadingIndicator.classList.remove('hidden');
                        
                        // 更新 iframe 源
                        iframe.src = examplePath;
                        
                        // 移除所有缩略图的 active 类
                        thumbnails.forEach(thumb => {
                            thumb.classList.remove('active');
                        });
                        
                        // 为当前选中的缩略图添加 active 样式
                        event.currentTarget.classList.add('active');
                    }
                    
                    // iframe 加载完成事件
                    iframe.onload = function() {
                        // 隐藏加载指示器
                        loadingIndicator.classList.add('hidden');
                    };
                    
                    // 为每个缩略图添加点击事件
                    thumbnails.forEach(thumbnail => {
                        thumbnail.addEventListener('click', function() {
                            const examplePath = this.getAttribute('data-example');
                            loadExample(examplePath);
                        });
                    });
                    
                    // 初始化：加载第一个示例
                    if (thumbnails.length > 0) {
                        const firstExamplePath = thumbnails[0].getAttribute('data-example');
                        thumbnails[0].classList.add('active'); // 为第一个添加 active 样式
                        loadExample(firstExamplePath);
                    }
                });
                </script>

                <style>
                /* 为 active 状态添加样式 */
                .example-thumbnail.active {
                    outline: 3px solid #3b82f6;
                    outline-offset: 2px;
                }

                /* 显示容器样式 */
                .display-container {
                    position: relative;
                    border-radius: 0.5rem;
                    overflow: hidden;
                }

                /* 加载指示器样式 */
                .loading-overlay {
                    display: flex;
                    align-items: center;
                    justify-content: center;
                }
                </style>
            </div>
        </section>

        <!-- Overview Section -->
        <section id="overview" class="mb-20">
            <div class="bg-white rounded-xl p-8 section-card">
                <h2 class="text-3xl font-bold text-center mb-8 gradient-text">Method Overview</h2>
                <div class="prose max-w-4xl mx-auto">
                    <p class="text-gray-700 leading-relaxed">
                        Figure 2 illustrates the overall pipeline of our method. Given an anchor RGB-D image I<sub>A</sub> containing an object of interest, our primary challenge is to estimate its 6D pose without a pre-existing 3D model, a common limitation for novel objects. To address this, as shown in the top-left of Figure 2, we first leverage recent advancements in single-view 3D generation to create a textured 3D model with a standardized orientation and scale (see Section 3.3). However, this generated model exists in a normalized space and lacks real-world scale.
                    </p>
                    <p class="text-gray-700 leading-relaxed mt-4">
                        To recover the object's true size and location in the anchor image frame, we introduce a coarse-to-fine alignment module (see Section 3.4). This module aligns the normalized generated model with the partial object observation in I<sub>A</sub>, simultaneously estimating the object's metric scale and initial 6D pose. Once the metric-scale model in the anchor view is established, we can efficiently estimate the object's pose in subsequent query RGB-D images I<sub>Q</sub> (top-right of Figure 2) using the aligned model and a robust pose estimation framework, including a pose selection module to handle potential object symmetries. The final relative transformation T<sub>A→Q</sub> is then computed from the absolute poses in both views.
                    </p>
                </div>

                <!-- 图片容器：控制宽度与居中 -->
                <div class="flex justify-center mt-12">
                    <div class="w-3/5"> <!-- 60% 宽度 -->
                        <img src="images/overview.png" alt="Method Overview" class="w-full rounded-lg shadow-lg">
                        <p class="mt-4 text-center text-gray-600">Figure 2: Overview of OnePoseviaGen</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Video Section -->
        <!-- <section id="video" class="mb-20">
            <div class="bg-white rounded-xl p-8 section-card">
                <h2 class="text-3xl font-bold text-center mb-8 gradient-text">Full Video</h2>

                <div class="max-w-4xl mx-auto">
                    <div class="relative mx-auto w-4/5 aspect-video rounded-lg overflow-hidden shadow-lg bg-black">
                        <video 
                            class="absolute inset-0 w-full h-full object-contain" 
                            src="full_video.mp4" 
                            controls 
                            playsinline>
                            Your browser does not support the video tag.
                        </video>
                    </div>
                </div>
            </div>
        </section> -->

        <!-- Demo Section -->
        <section id="demo" class="mb-20">
            <div class="bg-white rounded-xl p-8 section-card">
                <h2 class="text-3xl font-bold text-center mb-8 gradient-text">Online Demo</h2>
                <div class="prose max-w-4xl mx-auto mb-8">
                    <p class="text-gray-700 leading-relaxed">
                        Welcome to try our online demo below! You can upload your own images to experience the 6D pose estimation of OnePoseviaGen.
                        <span class="text-gray-500">(If loading is slow, please be patient or refresh the page to retry.)</span>
                    </p>
                </div>

                <!-- 外层容器：控制整体宽度（相对于 section），居中 -->
                <div class="max-w-6xl mx-auto">
                    <!-- 1:1 宽高比容器，正方形 -->
                    <div class="aspect-[8/5] rounded-lg overflow-hidden shadow-lg bg-gray-100">
                        <iframe 
                            src="https://aa0de9e105fcebc860.gradio.live" 
                            frameborder="0" 
                            class="w-full h-full rounded-lg"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen>
                        </iframe>
                    </div>
                </div>
            </div>
        </section>

        <!-- Experiments Section -->
        <section id="experiments" class="mb-20">
            <div class="bg-white rounded-xl p-8 section-card">
                <h2 class="text-3xl font-bold text-center mb-8 gradient-text">Experiments</h2>
                
                <div class="prose max-w-4xl mx-auto">
                    <p class="text-gray-700 leading-relaxed">
                        <span class="font-bold">Public datasets.</span> We evaluated our method on three challenging public datasets: YCBInEOAT (robotic interaction), Toyota-Light (TOYL) (challenging lighting), and LINEMOD Occlusion (LM-O) (cluttered, occluded, textureless objects).
                    </p>
                    <p class="text-gray-700 leading-relaxed mt-4">
                        <span class="font-bold">Real-world evaluation.</span> We performed two experiments in real-world settings: (1) 6D pose estimation for uncommon objects by generating synthetic training data via our domain randomization pipeline and testing on a calibrated real set, and (2) robotic manipulation tasks, establishing grasping setups using a ROKAE robot arm equipped with an XHAND1 dexterous hand, and two AgileX PiPERs, and measuring success rates against baselines.
                    </p>
                    <p class="text-gray-700 leading-relaxed mt-4">
                        <span class="font-bold">The two examples displayed below are randomly selected from our collection to enhance the page loading speed. Should you wish to explore further, simply click on the 'Load More' button to view additional examples.</span>
                    </p>
                    <p class="text-gray-700 leading-relaxed mt-4">
                    </p>
                </div>                
                
                <!-- 添加一个容器用于存放实验区块 -->
                <div id="experiments-container" class="space-y-8"></div>

                <!-- 添加“加载更多”按钮 -->
                <div class="flex justify-center mt-6">
                    <button id="load-more-btn" class="px-16 py-2 bg-blue-600 text-white rounded-full hover:bg-blue-700 transition">Load More</button>
                </div>

                <script>
                // 总共的实验数量
                const totalExperiments = 14;

                // 初始加载的实验数量
                let loadedExperiments = 2;

                // 随机生成不重复的实验编号数组
                function getRandomExperiments(num) {
                    const experiments = [];
                    while (experiments.length < num) {
                        const randomNum = Math.floor(Math.random() * totalExperiments) + 1;
                        if (!experiments.includes(randomNum)) {
                            experiments.push(randomNum);
                        }
                    }
                    return experiments;
                }

                // 生成指定编号的实验区块
                function generateExperimentHTML(num) {
                    return `
                        <!-- Experiment ${num} -->
                        <div class="max-w-4xl mx-auto grid grid-cols-1 md:grid-cols-5 gap-6 mb-8">
                            <div class="md:col-span-1">
                                <img src="videos/${num}/1.jpg" alt="Anchor Image" class="w-full rounded-lg shadow">
                                <p class="mt-2 text-center text-sm text-gray-600">Anchor Image</p>
                            </div>
                            <div class="md:col-span-4 grid grid-cols-1 sm:grid-cols-4 gap-4">
                                <div>
                                    <video controls class="w-full rounded-lg shadow" loop>
                                        <source src="videos/${num}/2.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                    <p class="mt-2 text-center text-sm text-gray-600">Aligned Model</p>
                                </div>
                                <div>
                                    <video controls class="w-full rounded-lg shadow" loop>
                                        <source src="videos/${num}/3.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                    <p class="mt-2 text-center text-sm text-gray-600">Original Video</p>
                                </div>
                                <div>
                                    <video controls class="w-full rounded-lg shadow" loop>
                                        <source src="videos/${num}/4.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                    <p class="mt-2 text-center text-sm text-gray-600">Rendered Video</p>
                                </div>
                                <div>
                                    <video controls class="w-full rounded-lg shadow" loop>
                                        <source src="videos/${num}/5.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                    <p class="mt-2 text-center text-sm text-gray-600">6D Pose Video</p>
                                </div>
                            </div>
                        </div>
                    `;
                }

                // 加载初始的实验区块
                function loadInitialExperiments() {
                    const initialExperiments = getRandomExperiments(loadedExperiments);
                    initialExperiments.forEach(num => {
                        document.getElementById('experiments-container').insertAdjacentHTML('beforeend', generateExperimentHTML(num));
                    });
                }

                // 加载更多的实验区块
                function loadMoreExperiments() {
                    const remainingExperiments = totalExperiments - loadedExperiments;
                    const numToLoad = Math.min(3, remainingExperiments); // 每次加载最多3个实验
                    const newExperiments = getRandomExperiments(numToLoad).filter(num => !Array.from(document.querySelectorAll('#experiments-container > div')).some(el => el.outerHTML.includes(`Experiment ${num}`)));
                    newExperiments.forEach(num => {
                        document.getElementById('experiments-container').insertAdjacentHTML('beforeend', generateExperimentHTML(num));
                    });
                    loadedExperiments += numToLoad;

                    // 如果所有实验都已加载，则隐藏“加载更多”按钮
                    if (loadedExperiments >= totalExperiments) {
                        document.getElementById('load-more-btn').style.display = 'none';
                    }
                }

                // 页面加载完成后执行
                document.addEventListener('DOMContentLoaded', function() {
                    loadInitialExperiments();
                    
                    // 绑定“加载更多”按钮点击事件
                    document.getElementById('load-more-btn').addEventListener('click', loadMoreExperiments);
                });
                </script>
                
                <!-- Results Comparison -->
                <div class="max-w-4xl mx-auto mt-12">
                    <img src="images\comparison.png" alt="Results Comparison" class="w-full rounded-lg shadow-lg">
                    <p class="mt-4 text-center text-gray-600">Figure 3: Qualitative comparison on the YCBInEOAT, LMO and TYOL dataset</p>
                </div>
                
                <div class="max-w-4xl mx-auto mt-8">
                    <img src="images\ycbineoat_qual_png_00.png" alt="Comparison Chart" class="w-full rounded-lg shadow-lg">
                    <p class="mt-4 text-center text-gray-600">Figure 3: Qualitative comparison on the YCBInEOAT dataset</p>
                </div>
            </div>
        </section>
    </main>

    <footer class="bg-gray-900 text-white py-12">
        <div class="container mx-auto px-4">
            <div class="flex flex-col md:flex-row justify-between items-center">
                <div class="mb-6 md:mb-0">
                    <h3 class="text-2xl font-bold mb-4">OnePoseviaGen</h3>
                    <p class="text-gray-400">Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation</p>
                </div>
                <div class="flex space-x-6">
                    <a href="https://arxiv.org" class="text-gray-400 hover:text-white transition">
                        <i class="fas fa-file-alt text-2xl"></i>
                    </a>
                    <a href="https://github.com/gzwsama/OnePoseviaGen" class="text-gray-400 hover:text-white transition">
                        <i class="fab fa-github text-2xl"></i>
                    </a>
                    <a href="mailto:contact@example.com" class="text-gray-400 hover:text-white transition">
                        <i class="fas fa-envelope text-2xl"></i>
                    </a>
                </div>
            </div>
            <div class="border-t border-gray-800 mt-8 pt-8 text-center text-gray-500">
                <p>© 2025 OnePoseviaGen Research Team. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <script>
        // Initialize Three.js scene
        function initThreeJS() {
            const container = document.getElementById('canvas-container');
            const width = container.clientWidth;
            const height = container.clientHeight;
            
            const scene = new THREE.Scene();
            const camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
            const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(width, height);
            container.appendChild(renderer.domElement);
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0x404040);
            scene.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
            directionalLight.position.set(1, 1, 1);
            scene.add(directionalLight);
            
            // Add a sample object (replace with your actual 3D model)
            const geometry = new THREE.BoxGeometry(2, 2, 2);
            const material = new THREE.MeshPhongMaterial({ 
                color: 0x3b82f6,
                specular: 0x111111,
                shininess: 30
            });
            const cube = new THREE.Mesh(geometry, material);
            scene.add(cube);
            
            camera.position.z = 5;
            
            // Animation loop
            function animate() {
                requestAnimationFrame(animate);
                cube.rotation.x += 0.01;
                cube.rotation.y += 0.01;
                renderer.render(scene, camera);
            }
            
            animate();
            
            // Handle window resize
            window.addEventListener('resize', () => {
                const width = container.clientWidth;
                const height = container.clientHeight;
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize(width, height);
            });
        }
        
        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', () => {
            initThreeJS();
            
            // Smooth scrolling for navigation links
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click', function(e) {
                    e.preventDefault();
                    document.querySelector(this.getAttribute('href')).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });
            
            // Animate sections when they come into view
            gsap.utils.toArray('.section-card').forEach(section => {
                gsap.from(section, {
                    scrollTrigger: {
                        trigger: section,
                        start: "top 80%",
                        toggleActions: "play none none none"
                    },
                    y: 50,
                    opacity: 0,
                    duration: 0.8,
                    ease: "power2.out"
                });
            });
        });
    </script>
</body>
</html>